⸻

main_fixed_b_resnet.py の構成と目的

はい、承知いたしました。main_fixed_b_resnet.py は、学習アルゴリズムの複雑さをすべて排除し、**「Shapley値の妥当性検証が、理想的な環境（静的な評価基準）で機能するか」**をテストするために設計された、シンプルな構成になっています。

⸻

main_fixed_b_resnet.py の構成

この手法のアーキテクチャは、**「サーバがBを、クライアントがAを管理する」**という点では main_sgd.py と同じですが、決定的な違いが1つあります。

Bserver 行列が一切学習（更新）されない点です。

⸻

1. 🤖 サーバ (FixedBServer) の役割：静的な「土俵」の提供
	•	B行列の初期化
サーバは起動時に一度だけ、Bserver 行列を「直交行列」として作成します。
	•	B行列の固定
この Bserver は requires_grad_(False) に設定され、学習対象から除外されます。サーバはオプティマイザ（SGD）を持ちません。
	•	ラウンドごとの動作
aggregate_and_update 関数は、Bserver を更新するロジックを一切持たず、「更新をスキップします」というログを出すだけです。

⸻

2. 💻 クライアント (Client) の役割：静的な B への適応
	•	パラメータの受信
クライアントは毎ラウンド、サーバから常に同じ（初期化時のままの）Bserver を受け取ります。
	•	学習
クライアントは、この固定された Bserver を使ってモデル
$W_0 + B^{server} A_i$ を構築し、loss.backward() を実行します。
	•	更新
Bserver は固定されているため、勾配は Ai 行列にのみ流れます。クライアントのオプティマイザは Ai だけを更新します。

⸻

3. 🎯 この実験の目的（仮説）

この構成は、SPSAやFedSGDによる Bserver の「動き」という不安定要因を排除しています。
クライアントは全員が「静的で公平な土俵（＝固定された Bserver）」に対して、自分の Ai を最適化します。

この理想的な環境で、最終ラウンドに以下の2つを検証します。

⸻

① Shapley値 ($\phi_i$)

$$
V(S) = \text{Accuracy}(W_0 + B^{server} \cdot \text{mean}(A_S))
$$

② Proxyスコア ($C_i$)

$$
C_i = \langle g_{A,i}, g_{A,global} \rangle
$$

③ ローカル精度 (Local Acc)

$$
\text{Accuracy}(W_0 + B^{server} \cdot A_i)
$$

⸻

仮説

もし Bserver が動かなければ、
	•	$\phi_i$（Aの連合による貢献）
	•	$C_i$（Aの勾配の貢献）
	•	Local Acc（Aの個別性能）

はすべて同じ「静的な土俵」で測られることになります。
その結果、main_sgd.py で観測された $\rho = -0.4$ のような「ミスマッチ」は解消され、
$\rho > 0.8$ の強い正の相関が観測されるはずです。

⸻
